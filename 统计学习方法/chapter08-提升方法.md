# 第八章　提升方法

提升方法是一种常见的统计学习方法。在分类任务中，它通过改变训练数据集中的样本权重来学习多个分类器，并且将这些分类器进行线性组合，达到提升分类的性能的目的。

## 8.1 AdaBoost算法

提升方法是基于这样一种思想：对于一个复杂的任务来说，将多个专家的判断进行适当的综合所得到的判断，要比其中任何一个专家单独的判断好。最能代表这一思想的算法是*AdaBoost*算法。

大多数提升方法都是改变训练数据的概率分布，或者说训练数据的权值分布；针对不同训练数据的分布调用弱学习算法学习一系列的弱分类器；再将这些弱分类器构成一个强分类器。但是如何来改变训练数据的权重或概率分布；又如何将这些弱分类器组合成一个强分类器呢。

针对第一个问题，*AdaBoost*算法的解决办法是，提高前一轮那些被弱分类器错误分类样本的权重，在不影响正确率的情况下降低那些被正确分类样本的权重；针对第二个问题，*AdaBoost*算法采用了加权多数表决的方法，具体做法是加大分类误差率较小的弱分类器的权重，使其在表决中起较大的作用，减少分类误差率较大的弱分类器的权重，使其在表决中其较小的作用。



