# 第六章　逻辑回归与最大熵模型

逻辑回归是统计学习中的经典分类方法。最大熵原理是概率模型学习的一个准则，将其推广到分类问题就可以得到最大熵模型。逻辑回归和最大熵模型都属于**对数线性模型**。

## 6.1 逻辑回归模型

二项逻辑回归模型可以由条件概率分布$P(Y|X)$表示：
$$
P(Y=1|X=x)=\frac{\exp(w^Tx+b)}{1+\exp(w^Tx+b)} \\
P(Y=0|X=x)=\frac{1}{1+\exp(w^Tx+b)}
$$
其中，$x\in R^n$是输入，$Y\in\{0,1\}$是输出，$w$和$b$分别是权值向量和偏置项。一个事件的**几率**是指该事件发生的概率与该事件不发生的概率之比。那么对于逻辑回归模型而言，由上面两个式子可得对数几率：
$$
\log \frac{P(Y=1|X=x)}{P(Y=0|X=x)}=w^Tx+b
$$
说明输出$Y=1$的对数几率是由输入$x$的线性函数表示的模型，即逻辑回归模型。换一个角度，考虑对输入$x$进行分类的线性函数$w^Tx+b$，其值域为实数域，通过逻辑回归模型将该线性函数转换为概率。对于该模型的参数$w$和$b$可以应用极大似然估计法来估计模型参数。

上面介绍的二项逻辑回归模型可以将它推广到用于多类分类问题的多项逻辑回归模型。假设输出类别的随机变量$Y$的取值集合为$\{1,2,3,\cdots,k\}$，那么多项逻辑回归模型为：
$$
P(Y=i|X=x)=\frac{\exp(w_i^Tx+b_i)}{1+\sum_{j=1}^{k-1}\exp(w_j^Tx+b_j)},\quad i=1,2,\cdots,k-1 \\
P(Y=k|X=x)=\frac{1}{1+\sum_{j=1}^{k-1}\exp(w_j^Tx+b_j)}
$$
其参数估计也可以使用最大似然估计法。

## 6.2 最大熵模型

最大熵模型是由**最大熵原理**推导实现的。最大熵原理认为，在学习概率模型的时候，在所有可能的概率模型中熵最大的模型是最好的模型。最大熵原理也可以表述为在满足约束条件的所有概率模型中选取熵最大的模型。

给定一个训练数据集
$$
T =\{(x_1,y_1),(x_2,y_2),\cdots, (x_N, y_N)\}
$$
其中$x_i \in \mathcal{X} \subseteq	 R^n​$表示输入，$y_i \in \mathcal{Y}​$表示输出，$\mathcal{X}​$和$\mathcal{Y}​$分别表示输入空间和输出空间，$N​$是训练样本个数。利用最大熵原理选择一个最好的分类模型，即对于任意给定的输入$x \in \mathcal{X}​$，以条件概率$P(Y=y|X=x)​$输出$y　\in \mathcal{Y}​$。

按照最大熵原理，先要保证模型满足已知的所有约束。那这些约束如何来提取？首先，从训练数据集$T​$中抽取若干个有利于分类的特征，然后要求这些特征在$T​$上关于经验分布$\widetilde{P}(X=x,Y=y)​$的数学期望与它们在模型中关于$P(X=x,Y=y)​$的数学期望相等。这样一个特征就对应一个约束。

对于任意一个特征函数$f$，记$E_{\widetilde{p}}(f)$表示$f$在训练数据集$T$上关于$\widetilde{P}(X=x,Y=y)$的数学期望，$E_{p}(f)$表示$f$关于模型上关于$P(X=x,Y=y)$的数学期望。按照数学期望的定义，则有：
$$
E_{\widetilde{p}}(f)=\sum_{x,y}\widetilde{P}(X=x,Y=y)f(x,y) \\
E_{p}(f)=\sum_{x,y}P(X=x,Y=y)f(x,y)
$$
由于$P(X=x,Y=y)$是未知量，而我们的目标是$P(Y=y|X=x)$。利用贝叶斯定理，有$P(X=x,Y=y)＝P(Y=y|X=x)P(X=x)$，但$P(X=x)$仍然是未知量，但是可以使用$\widetilde{P}(X=x)$来进行近似代替。这样可以将$E_{p}(f)$重写为：
$$
E_{p}(f)=\sum_{x,y}P(Y=y|X=x)\widetilde{P}(X=x)f(x,y)
$$
如果总共选取了$n$个特征，那么相应的就有$n$个特征函数$f_1,f_2,\cdots,f_n$，故有$n$个约束条件：
$$
E_{p}(f_i)=E_{\widetilde{p}}(f_i),\quad i=1,2,\cdots,n
$$
（**最大熵模型**）假设满足所有约束条件的模型集合为：
$$
\mathcal{C}=\{P\in \mathcal{P}|E_{p}(f_i)=E_{\widetilde{p}}(f_i), i=1,2,\cdots,n \}
$$
定义在条件概率分布$P(Y|X)$上的条件熵为：
$$
H(P(Y|X))=\sum_{x}P(X=x)H(Y|X=x) \\
=-\sum_{x}\widetilde{P}(X=x)\sum_{y}P(Y=y|X=x)\log P(Y=y|X=x)\\
\Longrightarrow H(P)=-\sum_{x}\widetilde{P}(x)\sum_{y}P(y|x)\log P(y|x)
$$
那么模型集合$\mathcal{C}$中条件熵$H(P)$最大的模型称为最大熵模型。式子中的对数是自然对数。

将最大熵模型求解过程转化为约束优化问题：
$$
\max_{P\in \mathcal{C}} \quad H(P)=-\sum_{x}\widetilde{P}(x)\sum_{y}P(y|x)\log P(y|x) \\
s.t. \quad E_{p}(f_i)=E_{\widetilde{p}}(f_i),\quad i=1,2,\cdots,n \\
\sum_{y}P(y|x)=1
$$
利用**拉格朗日乘子法**求解可得：
$$
P_{\lambda}(y|x)=\frac{1}{Z_{\lambda}(x)}\exp(\sum_{i=1}^n\lambda_i f_i(x,y) )
$$
其中$Z_{\lambda}(x)=\sum_{y}\exp(\sum_{i=1}^n \lambda_i f_i(x,y))$称为**规范化因子**，$\lambda_i$对应着特征的权重。

