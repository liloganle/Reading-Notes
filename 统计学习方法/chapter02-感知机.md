# 第二章　感知机

感知机是二分类的线性分类模型，属于判别式模型。感知机学习算法具有简单而易于实现的优点，具有原始形式、对偶形式两种形式。它是**神经网络**和**支持向量机**的基础。

## 2.1 感知机模型

假设输入空间（特征空间）是$n$维的，即$\mathcal{X} \subseteq R^n$，输出空间为$\mathcal{Y}=\{+1,-1\}$。对于输入$x \in \mathcal{X}$，其真实类别为$y\in \mathcal{Y}$。由输入空间映射到输出空间的函数形式如下：
$$
f(x)=\text{sign}(w \cdot x+b)
$$
称为感知机。其中，$w$和$b$分别为感知机模型的权重和偏置，sign是符号函数。

## 2.2 感知机学习策略

数据集线性可分性：对于数据集$T$中所有$y_{i}=+1$的实例$i$，有$w \cdot x_{i} + b>0 $；对于所有$y_{i}=-1$，有$w \cdot x_{i} + b<0 $，则称数据集$T$为线性可分数据集，否则称数据集$T$线性不可分。

假设训练数据集是线性可分的，感知机的学习目标是寻找到一个能够将训练集中的正样本和负样本完全正确分开的超平面。对于感知机的损失函数，一个自然选择是*误分类点的总数*；但是这样的损失函数不是连续可导函数，且不易有优化。另一个选择是*误分类点到超平面的总距离*，这是感知机算法所采用的。那么感知机模型$\text{sign}(w\cdot x + b)$的损失函数定义为：
$$
L(w,b)=-\sum_{x_i \in M}y_i (w\cdot x_i + b)
$$
其中，$M$是误分类样本集合。该损失函数也是感知机模型的经验损失函数。

## 2.3 感知机学习算法

感知机模型求解问题转化为最优化问题，所采用的方法为随机梯度下降法。假设误分类样本集合$M$是固定的，那么损失函数$L(w,b)$的梯度为：
$$
\nabla_{w}L(w,b)=-\sum_{x_i \in M}y_i x_i \\
\nabla_{b}L(w,b)=-\sum_{x_i \in M}y_i
$$
某个错分类样本$(x_i, y_i)$对$w,b$进行更新：
$$
w \leftarrow w + \eta y_i x_i \\
b \leftarrow b + \eta y_i
$$
其中$\eta(0<\eta<1)​$是学习率。
